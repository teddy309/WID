{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "LSS_competitionCode_Final.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4W9CjpJYJ7k",
        "colab_type": "text"
      },
      "source": [
        "# Mount to Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQEway1LYJZC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "1f562d61-044f-4756-b6e9-0ef3019aca6c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srqmSX9HW4GD",
        "colab_type": "text"
      },
      "source": [
        "# Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "ufMs40ixW4GE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import os\n",
        "from skimage import io\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "#--------------------------------------------------------------\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "\n",
        "\n",
        "#model hyperparameters\n",
        "model_output_size=4\n",
        "BATCH_SIZE = 8\n",
        "learning_rate=0.0001\n",
        "train_epoch=3 #10\n",
        "\n",
        "#EPOCH = 1000 #\n",
        "transforms = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.485,0.456,0.406],\n",
        "                                                                             std=[0.229,0.224,0.225])])\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-xIXlKyW4GH",
        "colab_type": "text"
      },
      "source": [
        "# DATA LOAD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "de33PweyW4GI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyDataset(Dataset):\n",
        "  def __init__(self, image_dir, label, transforms=None):\n",
        "    self.image_dir = image_dir\n",
        "    self.label = label\n",
        "    self.image_list = os.listdir(self.image_dir)\n",
        "    self.transforms = transforms\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.image_list)\n",
        "  \n",
        "  def __getitem__(self,idx):\n",
        "    # if torch.is_tensor(idx):\n",
        "    #   idx = idx.tolist()\n",
        "\n",
        "    image_name = os.path.join(self.image_dir, self.image_list[idx])\n",
        "    image = io.imread(image_name)\n",
        "\n",
        "    ### transform\n",
        "    image = transforms(image)\n",
        "\n",
        "    return (image,self.label)\n",
        "\n",
        "root = '/content/gdrive/My Drive/DL_repos/competition' #'/kaggle/input/swdl2020': root project repository\n",
        "#cheetah : 0 , jaguar : 1, tiger : 2, hyena : 3\n",
        "\n",
        "cheetah_train = MyDataset(root+\"/train/cheetah_train_resized\",0,transforms)\n",
        "jaguar_train = MyDataset(root+\"/train/jaguar_train_resized\",1,transforms)\n",
        "tiger_train = MyDataset(root+\"/train/tiger_train_resized\",2,transforms)\n",
        "hyena_train = MyDataset(root+\"/train/hyena_train_resized\",3,transforms)\n",
        "train_set = ConcatDataset([cheetah_train, jaguar_train, tiger_train, hyena_train])\n",
        "print(\"Number of Training set images : \", len(train_set))\n",
        "\n",
        "cheetah_val = MyDataset(root+\"/validation/cheetah_validation_resized\",0, transforms)\n",
        "jaguar_val = MyDataset(root+\"/validation/jaguar_validation_resized\",1, transforms)\n",
        "tiger_val = MyDataset(root+\"/validation/tiger_validation_resized\",2, transforms)\n",
        "hyena_val = MyDataset(root+\"/validation/hyena_validation_resized\",3,transforms)\n",
        "val_set = ConcatDataset([cheetah_val, jaguar_val, tiger_val, hyena_val])\n",
        "print(\"Numver of Validation set images : \", len(val_set))\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle = True) #params: train_set, 16, True\n",
        "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v97ltEPiW4GL",
        "colab_type": "text"
      },
      "source": [
        "# MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "iUSCBO7_W4GL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### YOUR MODEL#####\n",
        "class myResnet18(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(myResnet18, self).__init__()\n",
        "\n",
        "    #Define Convolution Operation(attributes)\n",
        "    self.resnet = models.resnet18() \n",
        "    self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
        "    self.fc = nn.Linear(in_features=1000, out_features=model_output_size, bias=True) #nn.Linear()\n",
        "\n",
        "  def forward(self, x):\n",
        "    input=x\n",
        "    #x = x.unsqueeze(0) # [3, 400, 400] -> [1, 3, 400, 400]\n",
        "    x = self.resnet(x).to(DEVICE) # [1, 3, 400, 400] -> [1, 1000]\n",
        "    x = x.view(-1, 1000) # INPUT [1, 64, 16, 16] -> OUTPUT [1, 64*16*16]  #input텐서를 지정된 output텐서로 펴주는 과정. [1,16384]로.\n",
        "    x = F.softmax(self.fc(x),dim=1)#torch.sigmoid(self.fc(x)) # INPUT [1, 64*16*16] -> OUTPUT [1, 1]\n",
        "    return x\n",
        "\n",
        "resnetModel = myResnet18()\n",
        "loss_func=nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "x = torch.rand(3, 400, 400)\n",
        "print('1- ',x.shape)\n",
        "x=x.unsqueeze(0)\n",
        "x=resnetModel.resnet(x)\n",
        "print('2- ',x.shape)\n",
        "x=x.view(-1,1000)\n",
        "print('3- ',x.shape)\n",
        "x=F.softmax(resnetModel.fc(x),dim=1)\n",
        "print('4- ',x.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxqRir-qW4GN",
        "colab_type": "text"
      },
      "source": [
        "# TRAIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Uca6WdbBW4GO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm.notebook import tqdm # for visualize training step. iterative한 것의 진행도를 보여줌. 트레이닝 정도를 시각화. \n",
        "\n",
        "def train(model, train_loader, optimizer, epoch):\n",
        "  model.train() #training mode\n",
        "  #for batch_idx, (image, target) in enumerate(train_loader): #target=label\n",
        "  for batch_idx, (image, target) in tqdm(enumerate(train_loader)):\n",
        "    data, target = image.to(DEVICE), target.to(DEVICE)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data).to(DEVICE) #cuda()\n",
        "    output=output.squeeze(1)\n",
        "    loss = loss_func(output,target) #nn.CrossEntropyLoss(output,target) \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch_idx % 150 == 0 :\n",
        "      print('Train Epoch : {} [{}/{} ({:.0f})%]\\tLoss: {:.6f}'\n",
        "      .format(epoch, batch_idx*len(image),len(train_loader.dataset), 100.*batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "def evaluate(model, test_loader):\n",
        "  model.eval() #validation mode\n",
        "  test_loss =0\n",
        "  correct =0\n",
        "  with torch.no_grad():\n",
        "    for (image, target) in tqdm(test_loader):\n",
        "      image, label = image.to(DEVICE), target.to(DEVICE)\n",
        "      output = model(image).to(DEVICE)\n",
        "\n",
        "      test_loss += F.cross_entropy(output, label, reduction='sum').item()\n",
        "      pred = output.max(1, keepdim=True)[1]\n",
        "      correct+= pred.eq(label.view_as(pred)).sum().item()\n",
        "  \n",
        "  test_loss /= len(test_loader.dataset)\n",
        "  test_accuracy = 100. * correct / len(test_loader.dataset)\n",
        "  return test_loss, test_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fx41UmQ3W4GQ",
        "colab_type": "text"
      },
      "source": [
        "# EXECUTE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "f8LaEBEuW4GQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#gpu model\n",
        "\n",
        "model=myResnet18().to(DEVICE)#\n",
        "criterion=nn.CrossEntropyLoss() #nn.BCELoss() #Binary Cross Entropy Loss\n",
        "optimizer= torch.optim.Adam(model.parameters(), lr=learning_rate) #params: net.params(),0.001,\n",
        "\n",
        "\n",
        "#????\n",
        "train_info=[]\n",
        "test_info=[]\n",
        "save_path='./ClassificationNetwork/'\n",
        "\n",
        "\n",
        "#training epoches\n",
        "for epoch in range(1, train_epoch+1):\n",
        "  print('#---------------------------------------------')\n",
        "  print('train epoch: {}'.format(epoch))\n",
        "  train(model, train_loader, optimizer, epoch)\n",
        "  #params: model(myCNN), DataLoader(train_set, 16, True), SGD(model.parameters(),lr=0.001,momentum=0.9) , EPOCH(1000)\n",
        "  print('validation epoch: {}'.format(epoch))\n",
        "  test_loss, test_accuracy = evaluate(model, val_loader)\n",
        "  print('[epoch {} Result] Test Loss : {:.4f}, Accuracy : {:.4f}%'.format(epoch, test_loss, test_accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMe-mfKFW4GS",
        "colab_type": "text"
      },
      "source": [
        "# TEST LOADER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Q22yVHxPW4GT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TestDataset(Dataset):\n",
        "  def __init__(self, image_dir, transforms=None):\n",
        "    self.image_dir = image_dir\n",
        "    self.image_list = os.listdir(self.image_dir)\n",
        "    self.transforms = transforms\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.image_list)\n",
        "  \n",
        "  def __getitem__(self,idx):\n",
        "    # if torch.is_tensor(idx):\n",
        "    #   idx = idx.tolist()\n",
        "\n",
        "    image_name = os.path.join(self.image_dir, self.image_list[idx])\n",
        "    image = io.imread(image_name)\n",
        "\n",
        "    ### transform\n",
        "    image = transforms(image)\n",
        "\n",
        "    return (image,self.image_list[idx].split('.')[0])\n",
        "\n",
        "\n",
        "test_set = TestDataset(root+\"/test404\", transforms) #test100\n",
        "test_loader = DataLoader(test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRPcGGCIW4GV",
        "colab_type": "text"
      },
      "source": [
        "# PREDICTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xzj2LdikW4GV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "#cheetah : 0 , jaguar : 1, tiger : 2, hyena : 3\n",
        "map = ['cheetah','jaguar','tiger','hyena']\n",
        "\n",
        "model.eval()\n",
        "df = pd.DataFrame(columns=['id','category'])\n",
        "with torch.no_grad():\n",
        "    #for (image, image_name) in test_loader:\n",
        "    for (image, image_name) in tqdm(test_loader):\n",
        "        image = image.to(DEVICE)\n",
        "        output = model(image).to(DEVICE)\n",
        "        pred = output.max(1, keepdim=True)[1]\n",
        "        print('iter:')\n",
        "        print('  1- ',image.shape)\n",
        "        print('  2- ',image_name)\n",
        "        print('  3- ',output.shape)\n",
        "        print('  4- ',pred)\n",
        "        \n",
        "        df = df.append(pd.DataFrame([[image_name[0], map[pred.squeeze().tolist()]]], columns=['id','category']))\n",
        "df #print df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMW6J_fAW4GX",
        "colab_type": "text"
      },
      "source": [
        "# SAVE CSV FILE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LePv81WbW4GX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv(root+'result404.csv', index=False)\n",
        "#df.to_csv(root+'/result.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}